"""
Music Dataset Loading Module
============================

Author: Sergie Code - Software Engineer & YouTube Programming Educator
Project: AI Tools for Musicians
Date: August 29, 2025

This module handles loading and processing of preprocessed music data
from the music-classification-preprocessing pipeline.
"""

import os
import json
import torch
from torch.utils.data import Dataset, DataLoader
import numpy as np
from typing import Dict, List, Optional, Tuple, Any
import logging

# Setup logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class MusicDataset(Dataset):
    """
    Dataset class for loading preprocessed music data.
    
    This dataset loads features and spectrograms generated by the
    music-classification-preprocessing pipeline and prepares them
    for model training.
    """
    
    def __init__(
        self,
        manifest_file: str,
        use_spectrograms: bool = True,
        use_features: bool = True,
        max_spectrogram_length: Optional[int] = None,
        augment: bool = False
    ):
        """
        Initialize the Music Dataset.
        
        Args:
            manifest_file: Path to the preprocessing manifest JSON file
            use_spectrograms: Whether to load spectrogram data
            use_features: Whether to load feature data
            max_spectrogram_length: Maximum length for spectrograms (for padding)
            augment: Whether to apply data augmentation
        """
        self.manifest_file = manifest_file
        self.use_spectrograms = use_spectrograms
        self.use_features = use_features
        self.max_spectrogram_length = max_spectrogram_length
        self.augment = augment
        
        # Load manifest
        with open(manifest_file, 'r') as f:
            self.manifest = json.load(f)
        
        self.files = self.manifest['files']
        
        # Extract unique labels for encoding
        self.genres = self._extract_unique_labels('genre')
        self.moods = self._extract_unique_labels('mood')
        self.keys = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B']
        
        # Create label encoders
        self.genre_to_idx = {genre: idx for idx, genre in enumerate(self.genres)}
        self.mood_to_idx = {mood: idx for idx, mood in enumerate(self.moods)}
        self.key_to_idx = {key: idx for idx, key in enumerate(self.keys)}
        
        logger.info(f"Loaded dataset with {len(self.files)} files")
        logger.info(f"Genres: {self.genres}")
        logger.info(f"Moods: {self.moods}")
        
    def _extract_unique_labels(self, label_type: str) -> List[str]:
        """Extract unique labels from the manifest."""
        labels = set()
        for file_info in self.files:
            if label_type in file_info and file_info[label_type]:
                labels.add(file_info[label_type])
        return sorted(list(labels)) if labels else [f"unknown_{label_type}"]
    
    def _extract_feature_vector(self, features_dict: Dict[str, Any]) -> np.ndarray:
        """
        Extract numeric feature vector from features dictionary.
        
        Expected features (103 total):
        - Temporal: 9 features
        - Spectral: 46 features  
        - Harmonic: 38 features
        - Rhythmic: 4 features
        - Statistical: 7 features
        """
        feature_vector = []
        
        # Temporal features (9)
        temporal_features = [
            'tempo', 'onset_rate', 'zero_crossing_rate_mean', 'zero_crossing_rate_std'
        ]
        for feature in temporal_features:
            feature_vector.append(features_dict.get(feature, 0.0))
        
        # Add more temporal features if available
        feature_vector.extend([0.0] * (9 - len(temporal_features)))
        
        # Spectral features (46) - MFCC and other spectral features
        spectral_features = [
            'spectral_centroid_mean', 'spectral_centroid_std',
            'spectral_bandwidth_mean', 'spectral_rolloff_mean'
        ]
        for feature in spectral_features:
            feature_vector.append(features_dict.get(feature, 0.0))
        
        # MFCC features (13 coefficients x 2 statistics = 26)
        for i in range(1, 14):
            mfcc_mean = f'mfcc_{i}_mean'
            mfcc_std = f'mfcc_{i}_std'
            feature_vector.append(features_dict.get(mfcc_mean, 0.0))
            feature_vector.append(features_dict.get(mfcc_std, 0.0))
        
        # Add padding for remaining spectral features
        feature_vector.extend([0.0] * (46 - len(feature_vector) + 9))
        
        # Harmonic features (38) - Chroma and tonal features
        for i in range(1, 13):
            chroma_mean = f'chroma_{i}_mean'
            chroma_std = f'chroma_{i}_std'
            feature_vector.append(features_dict.get(chroma_mean, 0.0))
            feature_vector.append(features_dict.get(chroma_std, 0.0))
        
        # Additional harmonic features
        harmonic_features = ['key_clarity', 'tonal_centroid_1']
        for feature in harmonic_features:
            feature_vector.append(features_dict.get(feature, 0.0))
        
        # Add padding for remaining harmonic features
        feature_vector.extend([0.0] * (38 - 24 - 2))
        
        # Rhythmic features (4)
        rhythmic_features = ['rhythm_complexity', 'beat_strength']
        for feature in rhythmic_features:
            feature_vector.append(features_dict.get(feature, 0.0))
        feature_vector.extend([0.0] * (4 - len(rhythmic_features)))
        
        # Statistical features (7)
        statistical_features = ['energy_mean', 'rms_energy_mean']
        for feature in statistical_features:
            feature_vector.append(features_dict.get(feature, 0.0))
        feature_vector.extend([0.0] * (7 - len(statistical_features)))
        
        # Ensure we have exactly 103 features
        feature_vector = feature_vector[:103]
        while len(feature_vector) < 103:
            feature_vector.append(0.0)
        
        return np.array(feature_vector, dtype=np.float32)
    
    def _load_spectrogram(self, spectrogram_path: str) -> torch.Tensor:
        """Load and process spectrogram data."""
        if not os.path.exists(spectrogram_path):
            logger.warning(f"Spectrogram file not found: {spectrogram_path}")
            # Return dummy spectrogram
            return torch.zeros(128, 100, dtype=torch.float32)
        
        try:
            spectrogram = np.load(spectrogram_path)
            spectrogram = torch.from_numpy(spectrogram).float()
            
            # Apply padding or truncation if max_length is specified
            if self.max_spectrogram_length:
                current_length = spectrogram.shape[1]
                if current_length > self.max_spectrogram_length:
                    # Truncate
                    spectrogram = spectrogram[:, :self.max_spectrogram_length]
                elif current_length < self.max_spectrogram_length:
                    # Pad
                    padding = self.max_spectrogram_length - current_length
                    spectrogram = torch.nn.functional.pad(spectrogram, (0, padding))
            
            return spectrogram
            
        except Exception as e:
            logger.error(f"Error loading spectrogram {spectrogram_path}: {e}")
            return torch.zeros(128, self.max_spectrogram_length or 100, dtype=torch.float32)
    
    def _load_features(self, features_path: str) -> torch.Tensor:
        """Load and process feature data."""
        if not os.path.exists(features_path):
            logger.warning(f"Features file not found: {features_path}")
            return torch.zeros(103, dtype=torch.float32)
        
        try:
            with open(features_path, 'r') as f:
                features_dict = json.load(f)
            
            feature_vector = self._extract_feature_vector(features_dict)
            return torch.from_numpy(feature_vector)
            
        except Exception as e:
            logger.error(f"Error loading features {features_path}: {e}")
            return torch.zeros(103, dtype=torch.float32)
    
    def __len__(self) -> int:
        return len(self.files)
    
    def __getitem__(self, idx: int) -> Dict[str, Any]:
        """Get a single data sample."""
        file_info = self.files[idx]
        
        data = {
            'filename': file_info['filename'],
            'duration': file_info.get('duration', 0.0)
        }
        
        # Load spectrogram if requested
        if self.use_spectrograms and 'spectrogram_file' in file_info:
            spectrogram = self._load_spectrogram(file_info['spectrogram_file'])
            # Add channel dimension for CNN
            data['spectrogram'] = spectrogram.unsqueeze(0)
        
        # Load features if requested
        if self.use_features and 'features_file' in file_info:
            features = self._load_features(file_info['features_file'])
            data['features'] = features
        
        # Load labels if available
        if 'genre' in file_info and file_info['genre']:
            genre_idx = self.genre_to_idx.get(file_info['genre'], 0)
            data['genre'] = torch.tensor(genre_idx, dtype=torch.long)
        
        if 'mood' in file_info and file_info['mood']:
            mood_idx = self.mood_to_idx.get(file_info['mood'], 0)
            data['mood'] = torch.tensor(mood_idx, dtype=torch.long)
        
        if 'bpm' in file_info and file_info['bpm']:
            data['bpm'] = torch.tensor(float(file_info['bpm']), dtype=torch.float32)
        
        # For key, we need to detect from features or use a default
        # This would typically come from the preprocessing pipeline
        data['key'] = torch.tensor(0, dtype=torch.long)  # Default to C
        
        return data


def create_data_loaders(
    manifest_file: str,
    batch_size: int = 32,
    train_split: float = 0.8,
    val_split: float = 0.1,
    test_split: float = 0.1,
    use_spectrograms: bool = True,
    use_features: bool = True,
    max_spectrogram_length: Optional[int] = None,
    num_workers: int = 0
) -> Tuple[DataLoader, DataLoader, DataLoader]:
    """
    Create train, validation, and test data loaders.
    
    Args:
        manifest_file: Path to the preprocessing manifest
        batch_size: Batch size for data loaders
        train_split: Fraction of data for training
        val_split: Fraction of data for validation
        test_split: Fraction of data for testing
        use_spectrograms: Whether to load spectrograms
        use_features: Whether to load features
        max_spectrogram_length: Maximum spectrogram length
        num_workers: Number of workers for data loading
        
    Returns:
        Tuple of (train_loader, val_loader, test_loader)
    """
    # Create full dataset
    full_dataset = MusicDataset(
        manifest_file=manifest_file,
        use_spectrograms=use_spectrograms,
        use_features=use_features,
        max_spectrogram_length=max_spectrogram_length
    )
    
    # Calculate split sizes
    total_size = len(full_dataset)
    train_size = int(train_split * total_size)
    val_size = int(val_split * total_size)
    test_size = total_size - train_size - val_size
    
    # Split dataset
    train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
        full_dataset, [train_size, val_size, test_size]
    )
    
    # Create data loaders
    train_loader = DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=num_workers,
        pin_memory=torch.cuda.is_available()
    )
    
    val_loader = DataLoader(
        val_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=num_workers,
        pin_memory=torch.cuda.is_available()
    )
    
    test_loader = DataLoader(
        test_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=num_workers,
        pin_memory=torch.cuda.is_available()
    )
    
    logger.info(f"Created data loaders - Train: {len(train_dataset)}, "
                f"Val: {len(val_dataset)}, Test: {len(test_dataset)}")
    
    return train_loader, val_loader, test_loader


def collate_fn(batch: List[Dict[str, Any]]) -> Dict[str, torch.Tensor]:
    """
    Custom collate function to handle variable-length spectrograms.
    
    Args:
        batch: List of data samples
        
    Returns:
        Batched data dictionary
    """
    batched_data = {}
    
    # Handle spectrograms with padding
    if 'spectrogram' in batch[0]:
        spectrograms = [item['spectrogram'] for item in batch]
        # Pad to the maximum length in the batch
        max_length = max(spec.shape[-1] for spec in spectrograms)
        
        padded_spectrograms = []
        for spec in spectrograms:
            if spec.shape[-1] < max_length:
                padding = max_length - spec.shape[-1]
                padded_spec = torch.nn.functional.pad(spec, (0, padding))
                padded_spectrograms.append(padded_spec)
            else:
                padded_spectrograms.append(spec)
        
        batched_data['spectrogram'] = torch.stack(padded_spectrograms)
    
    # Handle features
    if 'features' in batch[0]:
        features = [item['features'] for item in batch]
        batched_data['features'] = torch.stack(features)
    
    # Handle labels
    for label_type in ['genre', 'mood', 'key', 'bpm']:
        if label_type in batch[0]:
            labels = [item[label_type] for item in batch]
            batched_data[label_type] = torch.stack(labels)
    
    # Handle metadata
    batched_data['filename'] = [item['filename'] for item in batch]
    
    return batched_data


if __name__ == "__main__":
    # Example usage
    print("Music Dataset Module - Testing with dummy data")
    
    # This would normally use real manifest files from preprocessing
    dummy_manifest = {
        "dataset_name": "test_dataset",
        "total_files": 2,
        "files": [
            {
                "filename": "song1.wav",
                "duration": 180.0,
                "genre": "rock",
                "mood": "energetic",
                "bpm": 120,
                "features_file": "dummy_features.json",
                "spectrogram_file": "dummy_spectrogram.npy"
            },
            {
                "filename": "song2.wav",
                "duration": 200.0,
                "genre": "jazz",
                "mood": "calm",
                "bpm": 90,
                "features_file": "dummy_features2.json",
                "spectrogram_file": "dummy_spectrogram2.npy"
            }
        ]
    }
    
    print("Dummy manifest structure created for testing")
    print(f"Number of files: {dummy_manifest['total_files']}")
    print("Ready for integration with preprocessing pipeline!")
